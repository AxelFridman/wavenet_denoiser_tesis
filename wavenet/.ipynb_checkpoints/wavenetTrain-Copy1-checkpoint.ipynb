{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgPQ8uFiMWwg",
    "outputId": "58e76746-8757-432e-bfb9-a415371b87fb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import torch.fft\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torchvision.transforms as transforms\n",
    "import torchaudio.transforms as transformsaudio\n",
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import soundfile as sf\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import random\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "writer = SummaryWriter()\n",
    "%load_ext tensorboard\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params += params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "directoryBase = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Q2geUymaNvfH"
   },
   "outputs": [],
   "source": [
    "\n",
    "def pad_to_max_length(tensor1, tensor2):\n",
    "    max_length = max(tensor1.size(1), tensor2.size(1))\n",
    "\n",
    "    pad_tensor1 = torch.nn.functional.pad(tensor1, (0, max_length - tensor1.size(1)))\n",
    "    pad_tensor2 = torch.nn.functional.pad(tensor2, (0, max_length - tensor2.size(1)))\n",
    "\n",
    "    return pad_tensor1, pad_tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KRPe4vgOOROy"
   },
   "outputs": [],
   "source": [
    "inputSize = 32000\n",
    "class AudioCleaningDataset(Dataset):\n",
    "    def __init__(self, csv_file, audio_dir, noise_dir, reverb_dir, target_length=inputSize, maxRuido=0):\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        self.audio_dir = audio_dir\n",
    "        self.noise_dir = noise_dir\n",
    "        self.reverb_dir = reverb_dir\n",
    "        self.target_length = target_length\n",
    "        self.resampleo = transformsaudio.Resample(orig_freq=48000, new_freq=16000)  # Resampling\n",
    "        self.resampleoIR = transformsaudio.Resample(orig_freq=32000, new_freq=16000)  # Resampling\n",
    "\n",
    "        self.noise_files = os.listdir(noise_dir) # List all noise files\n",
    "        self.reverb_files = os.listdir(reverb_dir)\n",
    "        self.maxRuido = maxRuido\n",
    "        self.conv= transformsaudio.Convolve(mode=\"same\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        audio_file_name = os.path.join(self.audio_dir, self.dataframe.iloc[idx]['audio_file_name']+\".wav\")\n",
    "        waveform, sample_rate = torchaudio.load(audio_file_name)\n",
    "\n",
    "        waveformOriginal = self.resampleo(waveform)\n",
    "\n",
    "        #aca seleccionar\n",
    "        maximoPosible = len(waveformOriginal[0])-self.target_length\n",
    "        if(maximoPosible>1):\n",
    "          comienzoAleatorio = (random.randint(0,maximoPosible))\n",
    "          waveformOriginal = waveformOriginal[:,comienzoAleatorio:comienzoAleatorio+self.target_length]\n",
    "        #print(len(waveformOriginal[0]))\n",
    "\n",
    "\n",
    "        waveformSucia = waveformOriginal.clone()\n",
    "        padding = torch.zeros((1, max(self.target_length - waveformSucia.size(1),1)))\n",
    "\n",
    "        waveformOriginal = torch.cat((waveformOriginal, padding), dim=1)\n",
    "        waveformSucia = torch.cat((waveformSucia, padding), dim=1)\n",
    "\n",
    "        waveformOriginal = waveformOriginal[:,:self.target_length]\n",
    "        waveformSucia = waveformSucia[:,:self.target_length]\n",
    "\n",
    "        # Load a random noise file\n",
    "        noise_file_name = random.choice(self.noise_files)\n",
    "        noise_waveform, sample_Rate_ruido = torchaudio.load(os.path.join(self.noise_dir, noise_file_name))\n",
    "        # Repeat the noise waveform until it's at least as long as the audio waveform\n",
    "        while noise_waveform.size(1) < waveformSucia.size(1):\n",
    "            noise_waveform = torch.cat((noise_waveform, noise_waveform), dim=1)\n",
    "\n",
    "        # Trim the noise waveform to match the length of the audio waveform\n",
    "        noise_waveform = noise_waveform[:,:waveformSucia.size(1)]\n",
    "\n",
    "        # Add noise with a random signal-to-noise ratio between 0.01 and 0.1\n",
    "        snr = random.uniform(0.001, 0.01) #random.uniform(0.01, 0.1)\n",
    "\n",
    "        # LE SACO EL RUIDO SUCIO PARA ACELERAR APRENDIZAJE !!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        #waveformSucia = waveformSucia + noise_waveform * snr\n",
    "        whitenoise = random.uniform(0.0, self.maxRuido)\n",
    "        waveformSucia = waveformSucia + torch.randn_like(waveformOriginal) * whitenoise\n",
    "        return 1*waveformSucia, 1*waveformOriginal\n",
    "\n",
    "\n",
    "        IR_file_name = random.choice(self.reverb_files)\n",
    "        IR_waveform, sample_Rate_IR = torchaudio.load(os.path.join(self.reverb_dir, IR_file_name))\n",
    "        IR_waveform = self.resampleoIR(IR_waveform)\n",
    "\n",
    "        # Normalize impulse response\n",
    "        normalized_ir = IR_waveform / (IR_waveform.abs().max())\n",
    "\n",
    "        # Perform convolution\n",
    "        padded_signal, padded_filter = pad_to_max_length(waveformSucia, normalized_ir)\n",
    "\n",
    "        # Perform the FFT\n",
    "        fft_signal = torch.fft.fft(padded_signal)\n",
    "        fft_filter = torch.fft.fft(padded_filter)\n",
    "\n",
    "        # Perform the convolution in the frequency domain\n",
    "        fft_result = fft_signal * fft_filter\n",
    "\n",
    "        # Perform the inverse FFT to get the result in the time domain\n",
    "        result = torch.fft.ifft(fft_result)\n",
    "\n",
    "        # The result is complex, take the real part\n",
    "\n",
    "        # LE SACO EL REVERB PARA ACELERAR APRENDIZAJE !!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        #waveformSucia = result.real\n",
    "\n",
    "        padding = torch.zeros((1, max(self.target_length - waveformSucia.size(1),1)))\n",
    "\n",
    "        waveformOriginal = torch.cat((waveformOriginal, padding), dim=1)\n",
    "        waveformSucia = torch.cat((waveformSucia, padding), dim=1)\n",
    "\n",
    "        waveformOriginal = waveformOriginal[:,:self.target_length]\n",
    "        waveformSucia = waveformSucia[:,:self.target_length]\n",
    "\n",
    "       # waveformOriginal = (waveformOriginal - waveformOriginal.mean()) / waveformOriginal.std()\n",
    "       # waveformSucia = (waveformSucia - waveformSucia.mean()) / waveformSucia.std()\n",
    "       # Optional: Normalize convolved audio\n",
    "       # waveformSucia = waveformSucia / (waveformSucia.abs().max())\n",
    "       # waveformOriginal = waveformOriginal / (waveformOriginal.abs().max())\n",
    "\n",
    "        return 1*waveformSucia, 1*waveformOriginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rqo9d72ZAvve"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Neural network modules for WaveNet\n",
    "\n",
    "References :\n",
    "    https://arxiv.org/pdf/1609.03499.pdf\n",
    "    https://github.com/ibab/tensorflow-wavenet\n",
    "    https://qiita.com/MasaEguchi/items/cd5f7e9735a120f27e2a\n",
    "    https://github.com/musyoku/wavenet/issues/4\n",
    "\"\"\"\n",
    "\n",
    "class DilatedCausalConv1d(torch.nn.Module):\n",
    "    \"\"\"Dilated Causal Convolution for WaveNet\"\"\"\n",
    "    def __init__(self, channels, dilation=1):\n",
    "        super(DilatedCausalConv1d, self).__init__()\n",
    "\n",
    "        self.conv = torch.nn.Conv1d(channels, channels,\n",
    "                                    kernel_size=2, stride=1,  # Fixed for WaveNet\n",
    "                                    dilation=dilation,\n",
    "                                    padding=dilation,  # Fixed for WaveNet dilation\n",
    "                                    bias=False)  # Fixed for WaveNet but not sure\n",
    "        if torch.cuda.is_available():\n",
    "            self.conv = self.conv.to(device)\n",
    "\n",
    "    def init_weights_for_test(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv1d):\n",
    "                m.weight.data.fill_(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class CausalConv1d(torch.nn.Module):\n",
    "    \"\"\"Causal Convolution for WaveNet\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CausalConv1d, self).__init__()\n",
    "\n",
    "        # padding=1 for same size(length) between input and output for causal convolution\n",
    "        self.conv = torch.nn.Conv1d(in_channels, out_channels,\n",
    "                                    kernel_size=2, stride=1, padding=1,\n",
    "                                    bias=False)  # Fixed for WaveNet but not sure\n",
    "        if torch.cuda.is_available():\n",
    "            self.conv = self.conv.to(device)\n",
    "\n",
    "    def init_weights_for_test(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv1d):\n",
    "                m.weight.data.fill_(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv(x)\n",
    "\n",
    "        # remove last value for causal convolution\n",
    "        return output[:, :, :-1]\n",
    "\n",
    "\n",
    "class ResidualBlock(torch.nn.Module):\n",
    "    def __init__(self, res_channels, skip_channels, dilation):\n",
    "        \"\"\"\n",
    "        Residual block\n",
    "        :param res_channels: number of residual channel for input, output\n",
    "        :param skip_channels: number of skip channel for output\n",
    "        :param dilation:\n",
    "        \"\"\"\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.dilated = DilatedCausalConv1d(res_channels, dilation=dilation)\n",
    "        self.conv_res = torch.nn.Conv1d(res_channels, res_channels, 1)\n",
    "        self.conv_skip = torch.nn.Conv1d(res_channels, skip_channels, 1)\n",
    "\n",
    "        self.gate_tanh = torch.nn.Tanh()\n",
    "        self.gate_sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.conv_skip = self.conv_skip.to(device)\n",
    "            self.conv_res = self.conv_res.to(device)\n",
    "\n",
    "    def forward(self, x, skip_size):\n",
    "        \"\"\"\n",
    "        :param x:\n",
    "        :param skip_size: The last output size for loss and prediction\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        output = self.dilated(x)\n",
    "\n",
    "        # PixelCNN gate\n",
    "        gated_tanh = self.gate_tanh(output)\n",
    "        gated_sigmoid = self.gate_sigmoid(output)\n",
    "        gated = gated_tanh * gated_sigmoid\n",
    "\n",
    "        # Residual network\n",
    "        output = self.conv_res(gated)\n",
    "        output = output[:, :, 0:inputSize]\n",
    "\n",
    "        input_cut = x#[:, :, -output.size(2):]\n",
    "\n",
    "        output += input_cut\n",
    "\n",
    "        # Skip connection\n",
    "        skip = self.conv_skip(gated)\n",
    "        skip = skip[:, :, -skip_size:]\n",
    "\n",
    "        return output, skip\n",
    "\n",
    "\n",
    "class ResidualStack(torch.nn.Module):\n",
    "    def __init__(self, layer_size, stack_size, res_channels, skip_channels):\n",
    "        \"\"\"\n",
    "        Stack residual blocks by layer and stack size\n",
    "        :param layer_size: integer, 10 = layer[dilation=1, dilation=2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "        :param stack_size: integer, 5 = stack[layer1, layer2, layer3, layer4, layer5]\n",
    "        :param res_channels: number of residual channel for input, output\n",
    "        :param skip_channels: number of skip channel for output\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        super(ResidualStack, self).__init__()\n",
    "\n",
    "        self.layer_size = layer_size\n",
    "        self.stack_size = stack_size\n",
    "\n",
    "        self.res_blocks = self.stack_res_block(res_channels, skip_channels)\n",
    "\n",
    "    @staticmethod\n",
    "    def _residual_block(res_channels, skip_channels, dilation):\n",
    "        block = ResidualBlock(res_channels, skip_channels, dilation)\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            block = torch.nn.DataParallel(block)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            block.cuda()\n",
    "\n",
    "        return block\n",
    "\n",
    "    def build_dilations(self):\n",
    "        dilations = []\n",
    "\n",
    "        # 5 = stack[layer1, layer2, layer3, layer4, layer5]\n",
    "        for s in range(0, self.stack_size):\n",
    "            # 10 = layer[dilation=1, dilation=2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "            for l in range(0, self.layer_size):\n",
    "                dilations.append(2 ** l)\n",
    "\n",
    "        return dilations\n",
    "\n",
    "    def stack_res_block(self, res_channels, skip_channels):\n",
    "        \"\"\"\n",
    "        Prepare dilated convolution blocks by layer and stack size\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        res_blocks = []\n",
    "        dilations = self.build_dilations()\n",
    "\n",
    "        for dilation in dilations:\n",
    "            block = self._residual_block(res_channels, skip_channels, dilation)\n",
    "            res_blocks.append(block)\n",
    "\n",
    "        return res_blocks\n",
    "\n",
    "    def forward(self, x, skip_size):\n",
    "        \"\"\"\n",
    "        :param x:\n",
    "        :param skip_size: The last output size for loss and prediction\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        output = x\n",
    "        skip_connections = []\n",
    "\n",
    "        for res_block in self.res_blocks:\n",
    "            # output is the next input\n",
    "            output, skip = res_block(output, skip_size)\n",
    "\n",
    "            skip_connections.append(skip)\n",
    "\n",
    "\n",
    "        return torch.stack(skip_connections)\n",
    "\n",
    "\n",
    "class DensNet(torch.nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        \"\"\"\n",
    "        The last network of WaveNet\n",
    "        :param channels: number of channels for input and output\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        super(DensNet, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv1d(channels, channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = torch.nn.Conv1d(channels, channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.tan = torch.nn.Tanh()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.conv1 = self.conv1.to(device)\n",
    "            self.conv2 = self.conv2.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.tan(output)\n",
    "        output = self.conv2(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "X1LUHnVDXWGz"
   },
   "outputs": [],
   "source": [
    "#loss_fn = nn.L1Loss()\n",
    "#learning_rate = 0.0015\n",
    "#optimizer = torch.optim.AdamW(params=wavenetModel.parameters(), lr=learning_rate)\n",
    "#optimizerPost = torch.optim.AdamW(params=postnetModel.parameters(), lr=learning_rate)\n",
    "\n",
    "mel_transform1 = transformsaudio.MelSpectrogram(sample_rate = 16000,\n",
    "                                               n_fft = 2048,\n",
    "                                                n_mels = 120,\n",
    "                                                hop_length = 512).to('cuda')\n",
    "\n",
    "mel_transform2 = transformsaudio.MelSpectrogram(sample_rate = 16000,\n",
    "                                               n_fft = 512,\n",
    "                                                n_mels = 80,\n",
    "                                                hop_length = 128).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lOjB-ReSsR-Y"
   },
   "outputs": [],
   "source": [
    "def prepareSpectogram(melspect):\n",
    "    melspect = ((melspect - melspect.min()) / (melspect.max()-melspect.min()) + 0.00000001)\n",
    "    melspect=melspect.log10()\n",
    "    min_db = -6\n",
    "    # Clamp the values in the tensor to be no less than min_db\n",
    "    melspect = melspect.clamp(min=min_db)\n",
    "    return melspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XhoYwzuouEqi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    def melspectogramLoss(y_pred, true_y):\\n\\n      mel1true_y = (mel_transform1(true_y.to('cuda')))\\n      mel1y_pred = (mel_transform1(y_pred.to('cuda')))\\n      mel2true_y = (mel_transform2(true_y.to('cuda')))\\n      mel2y_pred = (mel_transform2(y_pred.to('cuda')))\\n\\n      mel1true_y = prepareSpectogram(mel1true_y)\\n      mel1y_pred = prepareSpectogram(mel1y_pred)\\n      mel2true_y = prepareSpectogram(mel2true_y)\\n      mel2y_pred = prepareSpectogram(mel2y_pred)\\n\\n      dif1 = (mel1true_y - mel1y_pred).abs().mean()\\n      dif2 = (mel2true_y - mel2y_pred).abs().mean()\\n      # Define the minimum dB value\\n\\n\\n      return dif1*15 + dif2*10\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"    def melspectogramLoss(y_pred, true_y):\n",
    "\n",
    "      mel1true_y = (mel_transform1(true_y.to('cuda')))\n",
    "      mel1y_pred = (mel_transform1(y_pred.to('cuda')))\n",
    "      mel2true_y = (mel_transform2(true_y.to('cuda')))\n",
    "      mel2y_pred = (mel_transform2(y_pred.to('cuda')))\n",
    "\n",
    "      mel1true_y = prepareSpectogram(mel1true_y)\n",
    "      mel1y_pred = prepareSpectogram(mel1y_pred)\n",
    "      mel2true_y = prepareSpectogram(mel2true_y)\n",
    "      mel2y_pred = prepareSpectogram(mel2y_pred)\n",
    "\n",
    "      dif1 = (mel1true_y - mel1y_pred).abs().mean()\n",
    "      dif2 = (mel2true_y - mel2y_pred).abs().mean()\n",
    "      # Define the minimum dB value\n",
    "\n",
    "\n",
    "      return dif1*15 + dif2*10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MelspectogramLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MelspectogramLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, true_y):\n",
    "        mel1true_y = (mel_transform1(true_y.to('cuda')))\n",
    "        mel1y_pred = (mel_transform1(y_pred.to('cuda')))\n",
    "        mel2true_y = (mel_transform2(true_y.to('cuda')))\n",
    "        mel2y_pred = (mel_transform2(y_pred.to('cuda')))\n",
    "\n",
    "        mel1true_y = prepareSpectogram(mel1true_y)\n",
    "        mel1y_pred = prepareSpectogram(mel1y_pred)\n",
    "        mel2true_y = prepareSpectogram(mel2true_y)\n",
    "        mel2y_pred = prepareSpectogram(mel2y_pred)\n",
    "\n",
    "        dif1 = (mel1true_y - mel1y_pred).abs().mean()\n",
    "        dif2 = (mel2true_y - mel2y_pred).abs().mean()\n",
    "\n",
    "        return dif1*15 + dif2*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.mel_loss = MelspectogramLoss()\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "\n",
    "    def forward(self, y_pred, true_y):\n",
    "        return self.mel_loss(y_pred, true_y) + self.l1_loss(y_pred, true_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Tq6IXvQW3AYR"
   },
   "outputs": [],
   "source": [
    "class WaveNet(pl.LightningModule):\n",
    "    def __init__(self, layer_size, stack_size, in_channels, res_channels):\n",
    "        \"\"\"\n",
    "        Stack residual blocks by layer and stack size\n",
    "        :param layer_size: integer, 10 = layer[dilation=1, dilation=2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "        :param stack_size: integer, 5 = stack[layer1, layer2, layer3, layer4, layer5]\n",
    "        :param in_channels: number of channels for input data. skip channel is same as input channel\n",
    "        :param res_channels: number of residual channel for input, output\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        super(WaveNet, self).__init__()\n",
    "\n",
    "        self.receptive_fields = self.calc_receptive_fields(layer_size, stack_size)\n",
    "\n",
    "        self.causal = CausalConv1d(in_channels, res_channels)\n",
    "\n",
    "        self.res_stack = ResidualStack(layer_size, stack_size, res_channels, in_channels)\n",
    "\n",
    "        self.densnet = DensNet(in_channels)\n",
    "\n",
    "        self.loss_fun = CombinedLoss()\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_receptive_fields(layer_size, stack_size):\n",
    "        layers = [2 ** i for i in range(0, layer_size)] * stack_size\n",
    "        num_receptive_fields = np.sum(layers)\n",
    "\n",
    "        return int(num_receptive_fields)\n",
    "\n",
    "    def calc_output_size(self, x):\n",
    "        output_size = int(x.size(2)) - self.receptive_fields\n",
    "\n",
    "        #self.check_input_size(x, output_size)\n",
    "\n",
    "        return inputSize\n",
    "\n",
    "    def check_input_size(self, x, output_size):\n",
    "        if output_size < 1:\n",
    "            raise InputSizeError(int(x.size(2)), self.receptive_fields, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        The size of timestep(3rd dimention) has to be bigger than receptive fields\n",
    "        :param x: Tensor[batch, timestep, channels]\n",
    "        :return: Tensor[batch, timestep, channels]\n",
    "        \"\"\"\n",
    "        output = x#.transpose(1, 2)\n",
    "\n",
    "        output_size = self.calc_output_size(output)\n",
    "\n",
    "        output = self.causal(output)\n",
    "\n",
    "        skip_connections = self.res_stack(output, output_size)\n",
    "\n",
    "        output = torch.sum(skip_connections, dim=0)\n",
    "\n",
    "\n",
    "        output = self.densnet(output)\n",
    "\n",
    "        return output#.transpose(1, 2).contiguous()\n",
    "    \n",
    "    def configure_optimizers(self, lr=learning_rate):\n",
    "        learning_rate = lr\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        X, y = train_batch\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        y_pred = self.forward(X)\n",
    "\n",
    "        # compute loss\n",
    "        loss = self.loss_fun(y_pred, y)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        rand = random.random()\n",
    "        if(rand<0.05):\n",
    "            torch.save(model, modeloNombre)\n",
    "        return loss\n",
    "    \n",
    "    def val_step(self, val_batch, batch_idx):\n",
    "        X, y = val_batch\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        # forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # compute loss\n",
    "        loss = self.loss_fun(y_pred, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "WGDcsGXnFUcj"
   },
   "outputs": [],
   "source": [
    "modeloNombre = directoryBase+'/modelos/wavenetReal/wavenetReplicaAudio.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#waveform, label = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "pIsVpbLrPM9V",
    "outputId": "07fcd081-8dd6-4769-b561-06a53db8f16e"
   },
   "outputs": [],
   "source": [
    "#Audio(data=waveform.cpu()[0], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "WY-A43_oPodH",
    "outputId": "a71d199d-6faf-4100-b97a-48f904d61aec",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Audio(data=label.cpu()[0], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def size_of_tensor(a):\n",
    "    return sys.getsizeof(a) + torch.numel(a)*a.element_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict(wavenetModel.named_parameters()).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WaveNet(layer_size=18, stack_size=2, in_channels=1, res_channels=128)\n",
    "model = torch.load(modeloNombre, map_location=torch.device('cuda'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type          | Params\n",
      "--------------------------------------------\n",
      "0 | causal    | CausalConv1d  | 256   \n",
      "1 | res_stack | ResidualStack | 0     \n",
      "2 | densnet   | DensNet       | 8     \n",
      "3 | loss_fun  | MSELoss       | 0     \n",
      "--------------------------------------------\n",
      "264       Trainable params\n",
      "0         Non-trainable params\n",
      "264       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd18bdf59ca4189a81e37ef8490fac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved. New best score: 0.000\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "#torch.multiprocessing.set_start_method('spawn')\n",
    "dataset = AudioCleaningDataset(directoryBase+'/CSV/audiosBastantes.csv', directoryBase+'/audiosDivididos/', directoryBase+'/audiosDivididos/ruidosPocos/', directoryBase+\"/audiosDivididos/reverbPocos\")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=24)\n",
    "# training\n",
    "early_stop_callback = EarlyStopping(monitor=\"train_loss\", min_delta=0.4, patience=1, verbose=True, mode=\"min\")\n",
    "\n",
    "trainer = pl.Trainer(accelerator='gpu', devices=1, max_epochs=1, log_every_n_steps=2, callbacks=[early_stop_callback])\n",
    "trainer.fit(model=model, train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, modeloNombre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "15oUUOrUA7iI"
   },
   "outputs": [],
   "source": [
    "wavenetModel = WaveNet( layer_size=18, stack_size=2, in_channels=1, res_channels=128)\n",
    "\n",
    "wavenetModel = torch.load(modeloNombre, map_location=torch.device('cuda'))\n",
    "wavenetModel = wavenetModel.to(device)\n",
    "#.load_state_dict(torch.load(modeloNombre))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'waveform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m size_of_tensor(\u001b[43mwaveform\u001b[49m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1024\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'waveform' is not defined"
     ]
    }
   ],
   "source": [
    "size_of_tensor(waveform)/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "a/1024/1024/1024, r/1024/1024/1024, t/1024/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with torch.no_grad():\n",
    "#wavenetModel(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PeVHJosnaZpO"
   },
   "outputs": [],
   "source": [
    "#modelPanoramico = WaveNetPanoramico(layer_size=18, stack_size=2, in_channels=1, res_channels=128)\n",
    "#modelPanoramico.load_state_dict(torch.load(modeloNombre))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sEqE-CwR3wd0"
   },
   "outputs": [],
   "source": [
    "#modeloPostnetNombre = '/content/drive/MyDrive/tesisPabloAxel/wavenet/modelos/wavenetReal/PostNetSimple12capas.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBCJQJZirDdu"
   },
   "outputs": [],
   "source": [
    "#postnetModel = PostNetSimple()\n",
    "#postnetModel.load_state_dict(torch.load(modeloPostnetNombre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KiZBEDdYQRKz"
   },
   "outputs": [],
   "source": [
    "#wavenetModel = modelCargado\n",
    "#WaveNet( layer_size=15, stack_size=2, in_channels=1, res_channels=128)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HOUQ1vuzXb1P"
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "dataset = AudioCleaningDataset(directoryBase+'/CSV/audiosBastantes.csv', directoryBase+'/audiosDivididos/', directoryBase+'/audiosDivididos/ruidosPocos/', directoryBase+\"/audiosDivididos/reverbPocos\")\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p6vDXnP1uYzR",
    "outputId": "98c31831-c786-4910-ae38-684dc391a121"
   },
   "outputs": [],
   "source": [
    "melspectogramLoss(waveform, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4HvLxmjhxmMK"
   },
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWROtyB-ghGW"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "OJIN73ueXi0i",
    "outputId": "ad31960c-a887-43f2-e4a8-533cb006f1d9"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    avgLossOfBatch = []\n",
    "    for i, (X, true_y) in enumerate(dataloader, 0):\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        y_pred = wavenetModel(X.to(device))\n",
    "        #y_pred_postnet = postnetModel(y_pred)\n",
    "        # calc losses\n",
    "\n",
    "        lossAudio = loss_fn(y_pred, true_y) * 100\n",
    "        lossSpect1, lossSpect2 = melspectogramLoss(y_pred, true_y)\n",
    "\n",
    "\n",
    "        loss = lossAudio + lossSpect1 + lossSpect2\n",
    "        #lossSpectPost1, lossSpectPost2 = melspectogramLoss(y_pred_postnet, true_y)\n",
    "        #lossPostnet = loss_fn(y_pred_postnet, true_y) * 10 + lossSpectPost1 + lossSpectPost2\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        #lossPostnet.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        #optimizerPost.step()\n",
    "\n",
    "        avgLossOfBatch.append(loss.item())\n",
    "        xs = 2917 * epoch + i\n",
    "        writer.add_scalar(\"Loss audio\", lossAudio, xs)\n",
    "        writer.add_scalar(\"Loss spect1\", lossSpect1, xs)\n",
    "        writer.add_scalar(\"Loss spect2\", lossSpect2, xs)\n",
    "        writer.add_scalar(\"Loss spect all\", lossSpect1 + lossSpect2, xs)\n",
    "\n",
    "        writer.add_scalar(\"Loss total\", loss, i)\n",
    "\n",
    "        if((i%1)==0):\n",
    "          print(str(round(100*(i)/(2917/batch_size),2)) + \"% del epoch \" + str(epoch))\n",
    "          prom = np.array(avgLossOfBatch).mean()\n",
    "          losses.append(prom)\n",
    "          avgLossOfBatch = []\n",
    "          #print(prom)\n",
    "          print(\"Perdida de wavenet: \")\n",
    "          print(loss)\n",
    "          print()\n",
    "          print(lossAudio)\n",
    "          print(lossSpect1)\n",
    "          print(lossSpect2)\n",
    "          #torch.save(wavenetModel.state_dict(), modeloNombre)\n",
    "          torch.save(wavenetModel, modeloNombre)\n",
    "            #torch.save(postnetModel.state_dict(), modeloPostnetNombre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHz_D5qdRLr1"
   },
   "outputs": [],
   "source": [
    "torch.save(wavenetModel, modeloNombre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqdDiK-4E3sk"
   },
   "outputs": [],
   "source": [
    "13 % 1==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIMwEY86ggBR"
   },
   "outputs": [],
   "source": [
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5GPj8DOOQpeF"
   },
   "outputs": [],
   "source": [
    "#predicho = wavenetModel(X).detach().to(\"cuda\")\n",
    "X = X.to(device)\n",
    "true_y = true_y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LMbjlLqZ5py"
   },
   "outputs": [],
   "source": [
    "wdet = wavenetModel(X).detach()\n",
    "predicho = wdet.cpu()\n",
    "X = X.cpu()\n",
    "true_y = true_y.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FpQ2WayMJIPR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1HLJvJxI2M0"
   },
   "outputs": [],
   "source": [
    "opin = [1,2,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2Qif9uIhlmj"
   },
   "outputs": [],
   "source": [
    "audioAnalizar = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrhzwWcJheSq"
   },
   "outputs": [],
   "source": [
    "lossSpect1, lossSpect2 = melspectogramLoss(predicho[audioAnalizar], true_y[audioAnalizar])\n",
    "loss1 = loss_fn(predicho[audioAnalizar], true_y[audioAnalizar])\n",
    "loss = loss1 + lossSpect1 + lossSpect2\n",
    "print(\"error de prediccion \" + str(loss.item()))\n",
    "\n",
    "\n",
    "lossSpect1t, lossSpect2t = melspectogramLoss(X[audioAnalizar], true_y[audioAnalizar])\n",
    "loss2 = loss_fn(X[audioAnalizar], true_y[audioAnalizar])\n",
    "loss2t = loss2 + lossSpect1t + lossSpect2t\n",
    "\n",
    "print(\"error sin hacer nada \" + str(loss2t.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlCnWvlYfSwN"
   },
   "outputs": [],
   "source": [
    "Audio(data=X.cpu()[audioAnalizar], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-vUnlapfP2D",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Audio(data=predicho.cpu()[audioAnalizar], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJwkKaDf0YmV"
   },
   "outputs": [],
   "source": [
    "Audio(data=predichoPost.cpu()[audioAnalizar], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lK2257kufdbA"
   },
   "outputs": [],
   "source": [
    "Audio(data=true_y.cpu()[audioAnalizar], rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FN6XNTbfj_Gs"
   },
   "outputs": [],
   "source": [
    "audioAnalizar = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.isnan(true_y[audioAnalizar]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(onda2)), (onda2.numpy()-onda.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(onda)), onda.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tL7qTgs0lqRd"
   },
   "outputs": [],
   "source": [
    "pos = 0\n",
    "delta = 32000\n",
    "onda = predicho[audioAnalizar][0][pos:pos+delta]\n",
    "onda2 = true_y[audioAnalizar][0][pos:pos+delta]\n",
    "#onda3 = X[audioAnalizar][0][pos:pos+delta]\n",
    "\n",
    "sns.lineplot(x=range(0,len(onda2)), y=onda2.numpy(), label=\"Real\")\n",
    "#sns.lineplot(x=range(0,len(onda3)), y=(onda3), label=\"Sucia\")\n",
    "sns.lineplot(x=range(0,len(onda)), y=onda.numpy(), label=\"Predicha\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z1FaXu6Hu0eg"
   },
   "outputs": [],
   "source": [
    "  mel1true_y = mel_transform1(true_y.to('cuda'))\n",
    "  mel1y_pred = mel_transform1(predicho.to('cuda'))\n",
    "  mel1sucio = mel_transform1(X.to('cuda'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "skeKllcatulH"
   },
   "outputs": [],
   "source": [
    "mel_spectrogram_db = transformsaudio.AmplitudeToDB()(mel1true_y).cpu()\n",
    "\n",
    "\n",
    "# Display the mel spectrogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(mel_spectrogram_db[0][0].detach().numpy(), cmap='viridis', origin='lower', aspect='auto')\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.title(\"Mel Spectrogram verdadero\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Mel Frequency Bin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fyC5VWOcvoAo"
   },
   "outputs": [],
   "source": [
    "mel_spectrogram_db2 = transformsaudio.AmplitudeToDB()(mel1y_pred).cpu()\n",
    "\n",
    "\n",
    "# Display the mel spectrogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(mel_spectrogram_db2[0][0].detach().numpy(), cmap='viridis', origin='lower', aspect='auto')\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.title(\"Mel Spectrogram predicho\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Mel Frequency Bin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZoMFkMFk9XK"
   },
   "outputs": [],
   "source": [
    "mel_spectrogram_db3 = transformsaudio.AmplitudeToDB()(mel1sucio).cpu()\n",
    "\n",
    "\n",
    "# Display the mel spectrogram\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(mel_spectrogram_db3[0][0].detach().numpy(), cmap='viridis', origin='lower', aspect='auto')\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.title(\"Mel Spectrogram sucio\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Mel Frequency Bin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvV-BuT9uRTr"
   },
   "outputs": [],
   "source": [
    "audioAnalizar = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IT2gRb26Jrqj"
   },
   "outputs": [],
   "source": [
    "import soundfile as sf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiurqNrVJgsi"
   },
   "outputs": [],
   "source": [
    "for audioAnalizar in opin:\n",
    "  sf.write('sucio'+str(audioAnalizar)+'.wav', np.ravel(X[audioAnalizar]), 16000, 'PCM_24')\n",
    "  sf.write('original'+str(audioAnalizar)+'.wav', np.ravel(true_y[audioAnalizar]), 16000, 'PCM_24')\n",
    "  sf.write('limpiado'+str(audioAnalizar)+'.wav', np.ravel(predicho[audioAnalizar][0]), 16000, 'PCM_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5WezPQKzV0x"
   },
   "outputs": [],
   "source": [
    "sf.write('sucio'+str(audioAnalizar)+'.wav', np.ravel(X[audioAnalizar]), 16000, 'PCM_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pURARsOjsobo"
   },
   "outputs": [],
   "source": [
    "sf.write('limpiadoEco'+str(audioAnalizar)+'.wav', np.ravel(predicho[audioAnalizar][0]), 16000, 'PCM_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tGT7A427sper"
   },
   "outputs": [],
   "source": [
    "sf.write('originalSinTocarWavenetReplica'+str(audioAnalizar)+'.wav', np.ravel(true_y[audioAnalizar]), 16000, 'PCM_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykFaePRHfwBX"
   },
   "outputs": [],
   "source": [
    "#dataloader give 1 example\n",
    "ini = time.time()\n",
    "for waveform, label in dataloader:\n",
    "    print(waveform.shape)\n",
    "    print(label.shape)\n",
    "    break\n",
    "fin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w66tjFfrsqf2"
   },
   "outputs": [],
   "source": [
    "out = modelPanoramico(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xak0MXc8u2Tq"
   },
   "outputs": [],
   "source": [
    "nuevow = WaveNet( layer_size=18, stack_size=2, in_channels=1, res_channels=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZtmnActyucZ"
   },
   "outputs": [],
   "source": [
    "#nuevow.load_state_dict(torch.load(modeloNombre), map_location=torch.device('cpu'))\n",
    "nuevow = torch.load(modeloNombre, map_location=torch.device('cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJl69TmxhhUR"
   },
   "outputs": [],
   "source": [
    "predicho = nuevow(waveform).detach().cpu()\n",
    "waveform = waveform.cpu().detach()\n",
    "true_y = label.cpu()\n",
    "X = waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7xiyE7QZiHmF"
   },
   "outputs": [],
   "source": [
    "lossSpect1, lossSpect2 = melspectogramLoss(predicho[audioAnalizar], true_y[audioAnalizar])\n",
    "loss1 = loss_fn(predicho[audioAnalizar], true_y[audioAnalizar])\n",
    "loss = loss1 + lossSpect1 + lossSpect2\n",
    "print(\"error de prediccion \" + str(loss.item()))\n",
    "\n",
    "lossSpect1t, lossSpect2t = melspectogramLoss(waveform[audioAnalizar], true_y[audioAnalizar])\n",
    "loss2 = loss_fn(waveform[audioAnalizar], true_y[audioAnalizar])\n",
    "loss2t = loss2 + lossSpect1t + lossSpect2t\n",
    "\n",
    "print(\"error sin hacer nada \" + str(loss2t.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BlKChZoagdq"
   },
   "outputs": [],
   "source": [
    "class WaveNetPanoramico(pl.LightningModule):\n",
    "    def __init__(self, layer_size, stack_size, in_channels, res_channels):\n",
    "        \"\"\"\n",
    "        Stack residual blocks by layer and stack size\n",
    "        :param layer_size: integer, 10 = layer[dilation=1, dilation=2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "        :param stack_size: integer, 5 = stack[layer1, layer2, layer3, layer4, layer5]\n",
    "        :param in_channels: number of channels for input data. skip channel is same as input channel\n",
    "        :param res_channels: number of residual channel for input, output\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        super(WaveNetPanoramico, self).__init__()\n",
    "\n",
    "        self.receptive_fields = self.calc_receptive_fields(layer_size, stack_size)\n",
    "\n",
    "        self.causal = CausalConv1d(in_channels, res_channels)\n",
    "\n",
    "        self.res_stack = ResidualStack(layer_size, stack_size, res_channels, in_channels)\n",
    "\n",
    "        self.densnet = DensNet(in_channels)\n",
    "\n",
    "        self.loss_fun = nn.MSELoss()\n",
    "        inp = layer_size*stack_size+res_channels+1\n",
    "        inp2 = math.floor(inp/2)\n",
    "        self.convFinal1 = nn.Conv1d(in_channels=layer_size*stack_size+res_channels+1,\n",
    "                                   out_channels=inp2,\n",
    "                                   kernel_size=15, stride=1,\n",
    "                                   dilation=1, padding=7, bias=True).to(device)\n",
    "        self.convFinal2 = nn.Conv1d(in_channels=inp2,\n",
    "                                   out_channels=1,\n",
    "                                   kernel_size=15, stride=1,\n",
    "                                   dilation=1, padding=7, bias=True).to(device)\n",
    "\n",
    "        self.convFinal3 = nn.Conv1d(in_channels=1,\n",
    "                                   out_channels=1,\n",
    "                                   kernel_size=101, stride=1,\n",
    "                                   dilation=1, padding=50, bias=False).to(device)\n",
    "\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    @staticmethod\n",
    "    def calc_receptive_fields(layer_size, stack_size):\n",
    "        layers = [2 ** i for i in range(0, layer_size)] * stack_size\n",
    "        num_receptive_fields = np.sum(layers)\n",
    "\n",
    "        return int(num_receptive_fields)\n",
    "\n",
    "    def calc_output_size(self, x):\n",
    "        output_size = int(x.size(2)) - self.receptive_fields\n",
    "\n",
    "        #self.check_input_size(x, output_size)\n",
    "\n",
    "        return inputSize\n",
    "\n",
    "    def check_input_size(self, x, output_size):\n",
    "        if output_size < 1:\n",
    "            raise InputSizeError(int(x.size(2)), self.receptive_fields, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        The size of timestep(3rd dimention) has to be bigger than receptive fields\n",
    "        :param x: Tensor[batch, timestep, channels]\n",
    "        :return: Tensor[batch, timestep, channels]\n",
    "        \"\"\"\n",
    "        output = x#.transpose(1, 2)\n",
    "        copiaConvolucionFinal = x.clone()\n",
    "\n",
    "        output_size = self.calc_output_size(output)\n",
    "\n",
    "        output = self.causal(output)\n",
    "\n",
    "        skip_connections = self.res_stack(output, output_size)\n",
    "\n",
    "\n",
    "\n",
    "        #en vez de sumar skip connections hago convolucion\n",
    "        #print(skip_connections.shape)\n",
    "        #output = torch.sum(skip_connections, dim=0)\n",
    "        skip_connections_squeezed = skip_connections.squeeze()\n",
    "        # Check the shape\n",
    "        # Swap the first two dimensions\n",
    "        skip_connections_squeezed = skip_connections_squeezed.transpose(0, 1)\n",
    "        output = torch.cat((output, copiaConvolucionFinal), dim=1)\n",
    "\n",
    "        output = torch.cat((output, skip_connections_squeezed), dim=1)\n",
    "\n",
    "        output = self.convFinal1(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.convFinal2(output)\n",
    "        #output = self.relu(output)\n",
    "        #output = self.convFinal3(output)\n",
    "\n",
    "        #output = self.densnet(output)\n",
    "\n",
    "        return output#.transpose(1, 2).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cig2EffMohfH"
   },
   "outputs": [],
   "source": [
    "class PostNetSimple(pl.LightningModule):\n",
    "  def __init__(self, layers=12):\n",
    "    super(PostNetSimple, self).__init__()\n",
    "    self.convInicial = nn.Conv1d(in_channels=1,\n",
    "                            out_channels=128,\n",
    "                            kernel_size=33, stride=1,\n",
    "                            dilation=1, padding=16, bias=True).to(\"cuda\")\n",
    "    self.totalLayers = layers\n",
    "    self.convs = []\n",
    "    for conv in range(0, layers):\n",
    "      self.convs.append(\n",
    "          nn.Conv1d(in_channels=128,\n",
    "                            out_channels=128,\n",
    "                            kernel_size=33, stride=1,\n",
    "                            dilation=1, padding=16, bias=True).to(\"cuda\")\n",
    "      )\n",
    "    self.convFinal = nn.Conv1d(in_channels=129,\n",
    "                            out_channels=1,\n",
    "                            kernel_size=33, stride=1,\n",
    "                            dilation=1, padding=16, bias=True).to(\"cuda\")\n",
    "    self.tan = nn.Tanh()\n",
    "\n",
    "  def forward(self, x):\n",
    "    xCopia = x.clone()\n",
    "    x = self.convInicial(x)\n",
    "    x = self.tan(x)\n",
    "    for conv in self.convs:\n",
    "      x = conv(x)\n",
    "      x = self.tan(x)\n",
    "    x = torch.cat((x, xCopia), dim=1)\n",
    "    x = self.convFinal(x)\n",
    "    return x"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
